{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import assembly as assembly\n",
    "import time as time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_index(trial_name):\n",
    "    '''\n",
    "    This function return the starting sample index for each trial, ignore the ending sample, because we donnot need it\n",
    "    '''\n",
    "    end_index = trial_info.loc[\"Cumulative Samples\"][trial_name]\n",
    "    start_index = trial_info.loc[\"Cumulative Samples\"][trial_name] - trial_info.loc[\"Samples\"][trial_name]\n",
    "    return start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    '''\n",
    "    return:\n",
    "    spike_clusters: list of neuron's ID in a single tetrode\n",
    "    spike_times: list of index of timestamp for each activity\n",
    "    To get specific time, do spike_times / fs \n",
    "    '''\n",
    "    spike_clusters = np.load(\"spike_clusters.npy\").reshape(-1)\n",
    "    spike_times = np.load(\"spike_times.npy\").reshape(-1)\n",
    "    cluster_df = pd.read_csv(\"cluster_group.tsv\",sep='\\t')\n",
    "    return spike_clusters, spike_times, cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cluster_type(cluster_df):\n",
    "    '''\n",
    "    input: a dataframe contain two columns: \"cluster_id\", \"group\"\n",
    "    output: a list contain all neuron id which is not noise\n",
    "    '''\n",
    "    good_cluster = cluster_df[(cluster_df[\"group\"] != \"noise\") & (cluster_df[\"group\"] != \"mua\")]\n",
    "    return list(good_cluster[\"cluster_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_index(spike_times, spike_clusters, samples_index_list):\n",
    "    '''\n",
    "    Get the index of spike_times and spike_cluster to split each trial\n",
    "    '''\n",
    "    samples_index_list_copy = samples_index_list.copy()\n",
    "    splite_index = []\n",
    "    splite_index.append(0)\n",
    "    for index in range(len(spike_times) - 1):\n",
    "        if (spike_times[index] - samples_index_list_copy[0]) * (spike_times[index + 1] - samples_index_list_copy[0]) <= 0:\n",
    "            splite_index.append(index + 1)\n",
    "            samples_index_list_copy.remove(samples_index_list_copy[0])\n",
    "    splite_index.append(len(spike_times) -1)\n",
    "    return splite_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trial(spike_times, spike_clusters, split_index):\n",
    "    '''\n",
    "    The trial information can be found trial_info column name\n",
    "    Split two list into different trials\n",
    "    return data structure is a dictionary with trial name as key, pairs of (spike_time, spike_index) as value\n",
    "    '''\n",
    "    trial_dict = {}\n",
    "    for trial_index in range(len(trial_info.columns)):\n",
    "        trial_samples = list(zip(spike_times[split_index[trial_index]:split_index[trial_index + 1]], \n",
    "                            spike_clusters[split_index[trial_index]:split_index[trial_index + 1]]))\n",
    "        index = trial_info.columns[trial_index]\n",
    "        trial_dict[index] = trial_samples\n",
    "    return trial_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_trial_dict(trial_dict, trial_name):\n",
    "    '''\n",
    "    upzip the zipped pair in dictionary values\n",
    "    '''\n",
    "    unzipped_object = zip(*trial_dict[trial_name])\n",
    "    unzipped_list = list(unzipped_object)\n",
    "    spike_times = list(unzipped_list[0])\n",
    "    spike_clusters = list(unzipped_list[1])\n",
    "    return spike_times, spike_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunk_samples(spike_clusters, spike_times, trial_name):\n",
    "    '''\n",
    "    trunk the samples by removing their tails\n",
    "    '''\n",
    "    for sample_index in range(len(spike_times)):\n",
    "        start_index, end_index = get_sample_index(trial_name)\n",
    "        if spike_times[sample_index] <= trial_info.loc[\"modified_samples\"][trial_name] + start_index:\n",
    "            cut_index = sample_index\n",
    "    return spike_times[:cut_index], spike_clusters[:cut_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_structure(spike_clusters, spike_times, cluster_df, trial_name):\n",
    "    step_size = 0.025*fs\n",
    "    start_index, end_index = get_sample_index(trial_name)\n",
    "    sample_duration = trial_info.loc[\"modified_samples\"][trial_name]\n",
    "    end_trucked_index = start_index + sample_duration\n",
    "    bins = np.arange(start = start_index, stop = end_trucked_index, step = step_size)    \n",
    "#     NData = np.zeros([np.max(spike_clusters) + 1, bins.shape[0] + 1])\n",
    "    NData = np.zeros([max(list(cluster_df[\"cluster_id\"])) + 1, bins.shape[0] + 1])\n",
    "    reminder = spike_times[-1] - bins[-1]\n",
    "    return step_size, bins, NData, reminder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_filled_matrix(spike_times, spike_clusters, NData, step_size, bins):\n",
    "    for index in range(len(spike_times)):\n",
    "        neuron_id = spike_clusters[index]\n",
    "        bin_index = int((spike_times[index] - bins[0]) / step_size)\n",
    "        NData[neuron_id][bin_index] += 1\n",
    "    return NData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actmat_for_a_trial(absolute_path, trial_name):\n",
    "    os.chdir(absolute_path)\n",
    "    spike_clusters, spike_times, cluster_df = load_data()\n",
    "#     spike_times, spike_clusters = get_useful_spike(spike_clusters, spike_times, cluster_df)\n",
    "    split_index = get_split_index(spike_times, spike_clusters, samples_index_list)\n",
    "    trial_dict = split_trial(spike_times, spike_clusters, split_index)\n",
    "    spike_times, spike_clusters = unzip_trial_dict(trial_dict, trial_name)\n",
    "    spike_times, spike_clusters = trunk_samples(spike_clusters, spike_times, trial_name)\n",
    "    step_size, bins, NData, reminder = get_matrix_structure(spike_clusters, spike_times, cluster_df, trial_name)\n",
    "    actmat = get_single_filled_matrix(spike_times, spike_clusters, NData, step_size, bins)\n",
    "    neuron_id = []\n",
    "    for row_index in range(len(actmat)):\n",
    "        if row_index in check_cluster_type(cluster_df):\n",
    "            neuron_id.append(\"RGS_PROJECT_RGS14_HC_Rn3_SD14_T\" + absolute_path[absolute_path.index('Tetrode_') + 8 : (absolute_path.index('phy_') - 1)] \n",
    "                             + '_UID' + str(row_index))\n",
    "        else:\n",
    "            neuron_id.append(\"null\")\n",
    "    actmat[:, len(actmat[0]) - 2] = actmat[:, len(actmat[0]) - 2] + actmat[:, len(actmat[0]) - 1]\n",
    "    actmat = actmat[:, : len(actmat[0]) - 1]\n",
    "    return actmat, neuron_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_all_file_for_a_trial(absolute_path_list, trial_name):\n",
    "    neuron_id_all = []\n",
    "    actmat, neuron_id = get_actmat_for_a_trial(absolute_path_list[0], trial_name)\n",
    "    neuron_id_all.append(neuron_id)\n",
    "    for path_index in range(1, len(absolute_path_list)):\n",
    "        matrix, neuron_id = get_actmat_for_a_trial(absolute_path_list[path_index], trial_name)\n",
    "        actmat = np.concatenate((actmat, matrix), axis=0)\n",
    "        neuron_id_all.append(neuron_id)\n",
    "    neuron_name = [item for sublist in neuron_id_all for item in sublist]\n",
    "    return actmat, neuron_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Change the path into the folder where you put the Trial_durations.xls file'''\n",
    "'''Ã‡hange the date into actual date performing the experiment'''\n",
    "\n",
    "#path = \"D:\\Internship_Radbound\\Cell_Assemblying_Test\\Cell_assembly_yuqin\"\n",
    "path = \"/media/adrian/6aa1794c-0320-4096-a7df-00ab0ba946dc/Cell_assembly_yuqin\"\n",
    "date = \"xx\"\n",
    "os.chdir(path)\n",
    "trial_info = pd.read_excel('Trial_durations.xls', index_col = 0)  \n",
    "final_samples = trial_info[\"2019-11-16_15-10-05_Post_Trial5\"][\"Cumulative Samples\"]\n",
    "samples_index_list = list(trial_info.loc[\"Cumulative Samples\"])\n",
    "fs = 30000\n",
    "#Modified the minutes and samples by removing the tail\n",
    "trial_info.loc[\"modified_minutes\"] = [45.0, 5.0, 45.0, 5.0, 45.0, 5.0, 45.0, 5.0, 45.0, 5.0, 180.0]\n",
    "trial_info.loc[\"modified_samples\"] = trial_info.loc[\"modified_minutes\"]* 60 * 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Change absolute_path_list and trial_name_list'''\n",
    "\n",
    "absolute_path_list = [path + \"/cortex/Tetrode_6/phy_MS4\",\n",
    "                      path + \"/cortex/Tetrode_7/phy_AGR\",\n",
    "                      path + \"/cortex/Tetrode_8/phy_AGR\",\n",
    "                      path + \"/cortex/Tetrode_9/phy_AGR\",\n",
    "                      path + \"/cortex/Tetrode_10/phy_MS4\",\n",
    "                      path + \"/cortex/Tetrode_11/phy_AGR\",\n",
    "                      path + \"/cortex/Tetrode_12/phy_AGR\",\n",
    "                      path + \"/cortex/Tetrode_13/phy_AGR\",\n",
    "                      path + \"/cortex/Tetrode_14/phy_AGR\",\n",
    "                      path + \"/cortex/Tetrode_15/phy_AGR\"]\n",
    "\n",
    "trial_name_list = list(trial_info.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actmat, neuron_id_all = iterate_all_file_for_a_trial([absolute_path_list[4]], trial_name_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolder(absolute_dir):\n",
    "    if not os.path.exists(absolute_dir):\n",
    "        os.makedirs(absolute_dir)\n",
    "        os.chdir(absolute_dir)\n",
    "    else:\n",
    "        os.chdir(absolute_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial_name in trial_name_list:\n",
    "    final_matrix, neuron_name = iterate_all_file_for_a_trial(absolute_path_list, trial_name)\n",
    "    createFolder(path + '/' + date)\n",
    "    np.save(trial_name + \"_actmat\", final_matrix)\n",
    "    np.save(trial_name + \"_neuron_name\", neuron_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
